{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution on Tree Models**\n",
    "\n",
    "BAS 474\n",
    "\n",
    "Charles Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:51.729575Z",
     "start_time": "2020-03-29T03:18:51.662Z"
    }
   },
   "outputs": [],
   "source": [
    "lib <- library\n",
    "library <- function(...){\n",
    "    suppressMessages(lib(...))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.284580Z",
     "start_time": "2020-03-29T03:18:51.665Z"
    }
   },
   "outputs": [],
   "source": [
    "library(regclass)  \n",
    "library(rpart)\n",
    "library(randomForest)\n",
    "library(gbm)\n",
    "library(caret)\n",
    "library(pROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Partition\n",
    "\n",
    "A partition currently contains the following individuals (class labels and the values of their predictor variables are provided). Relevant subsets of the data are as below:\n",
    "\n",
    "Sorted on class (useful for part a)\n",
    "\n",
    "Class | Rating |  Gender\n",
    "------|--------|--------\n",
    "A     | 0.2    | Male\n",
    "A     | 2.4    | Female\n",
    "A     | 5.7    | Male\n",
    "B     | 1.8    | Female\n",
    "B     | 4.8    | Female\n",
    "B     | 5.7    | Male\n",
    "B     | 7.9    | Male\n",
    "B     | 9.2    | Female\n",
    "\n",
    "Sorted on Rating (useful for part b)\n",
    "\n",
    "Class | Rating |  Gender\n",
    "------|--------|--------\n",
    "A     | 0.2    | Male\n",
    "B     | 1.8    | Female\n",
    "A     | 2.4    | Female\n",
    "B     | 4.8    | Female\n",
    "B     | 5.7    | Male\n",
    "A     | 5.7    | Male\n",
    "B     | 7.9    | Male\n",
    "B     | 9.2    | Female\n",
    "\n",
    "Sorted on Gender (useful for part c)\n",
    "\n",
    "Class | Rating |  Gender\n",
    "------|--------|--------\n",
    "A     | 0.2    | Male\n",
    "B     | 5.7    | Male\n",
    "A     | 5.7    | Male\n",
    "B     | 7.9    | Male\n",
    "B     | 1.8    | Female\n",
    "A     | 2.4    | Female\n",
    "B     | 4.8    | Female\n",
    "B     | 9.2    | Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T17:05:50.969008Z",
     "start_time": "2020-03-28T17:05:50.915Z"
    }
   },
   "source": [
    "a.  What is the Gini index of this partition?\n",
    "\n",
    "**Response:** 0.46875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.542986Z",
     "start_time": "2020-03-29T03:18:51.801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.46875"
      ],
      "text/latex": [
       "0.46875"
      ],
      "text/markdown": [
       "0.46875"
      ],
      "text/plain": [
       "[1] 0.46875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pA <- 3/8  #calculate proportions of each class\n",
    "pB <- 5/8\n",
    "g <- 1- pA^2 - pB^2 #Gini\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  If this partition was split using the rule `Rating < 3.6` vs. `Rating >= 3.6`, what would be Gini indices of the two resulting partitions as well as the *reduction* in the Gini index when using this rule?   If the `cp` value for the tree was 0.01 (default in R), would this partition be split (assuming it's the first rule added to the model)?  In other words, is the reduction larger than `cp`?\n",
    "\n",
    "**Response:**  The reduction works out to be 0.10208.  Since this is (much) larger than `cp`, so yes the partition could be split using this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.603459Z",
     "start_time": "2020-03-29T03:18:51.853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.366666666666667"
      ],
      "text/latex": [
       "0.366666666666667"
      ],
      "text/markdown": [
       "0.366666666666667"
      ],
      "text/plain": [
       "[1] 0.3666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.102083333333333"
      ],
      "text/latex": [
       "0.102083333333333"
      ],
      "text/markdown": [
       "0.102083333333333"
      ],
      "text/plain": [
       "[1] 0.1020833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Splitting Rating < 3.6 vs. Rating >= 3.6\n",
    "pA <- 2/3; pB <- 1/3  #calculate proportions and Gini index of \"left\" partition\n",
    "g1 <- 1- pA^2 - pB^2\n",
    "pA <- 1/5; pB <- 4/5  #calculate proportions and Gini index of \"right\" partition\n",
    "g2 <- 1- pA^2 - pB^2\n",
    "w1 <- 3/8; w2 <- 5/8\n",
    "g.rating <- w1*g1 + w2*g2  #Gini of split is weighted sum of gini inidices of resulting partitions\n",
    "g.rating\n",
    "g-g.rating  #reduction in Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.  If this partition was split using the rule `Gender=Female` vs. `Gender=Male`, what would be the Gini indices of the two resulting partitions as well as the the *reduction* in the Gini index?   If the `cp` value for the tree was 0.01 (default in R), would this partition be split (assuming it's the first rule added to the model)?  In other words, is the reduction larger than `cp`?\n",
    "\n",
    "**Response:**  The reduction works out to be 0.03125.  Since this is larger than `cp`, so yes the partition could be split using this rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.662932Z",
     "start_time": "2020-03-29T03:18:51.904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.4375"
      ],
      "text/latex": [
       "0.4375"
      ],
      "text/markdown": [
       "0.4375"
      ],
      "text/plain": [
       "[1] 0.4375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.03125"
      ],
      "text/latex": [
       "0.03125"
      ],
      "text/markdown": [
       "0.03125"
      ],
      "text/plain": [
       "[1] 0.03125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Splitting Male vs. Female\n",
    "pA <- 2/4; pB <- 2/4  #calculate proportions and Gini index of Male partition\n",
    "g1 <- 1- pA^2 - pB^2\n",
    "pA <- 1/4; pB <- 3/4  #calculate proportions and Gini index of Female partition\n",
    "g2 <- 1- pA^2 - pB^2\n",
    "w1 <- 4/8; w2 <- 4/8\n",
    "g.gender <- w1*g1 + w2*g2  #Gini of split is weighted sum of gini inidices of resulting partitions\n",
    "g.gender\n",
    "g-g.gender  #reduction in Gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.  Which of the two rules:  `Rating < 3.6` vs. `Rating >= 3.6` or `Gender=Female` vs. `Gender=Male` is better and why?\n",
    "\n",
    "**Response:**  The `Rating < 3.6` vs. `Rating >= 3.6` is better because it gives the largest reduction in the Gini index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Partition\n",
    "\n",
    "A partition model currently contains the following individuals (y-values and the values of their predictor variables are provided).\n",
    "\n",
    "Sorted on Rating\n",
    "\n",
    "y      | Rating |  Gender\n",
    "-------|--------|--------\n",
    "8      | 0.2    | Male\n",
    "4      | 1.8    | Female\n",
    "5      | 2.4    | Female\n",
    "16     | 4.8    | Female\n",
    "12     | 5.7    | Male\n",
    "11     | 5.7    | Male\n",
    "11     | 7.9    | Male\n",
    "13     | 9.2    | Female\n",
    "\n",
    "Sorted on Gender\n",
    "\n",
    "y      | Rating |  Gender\n",
    "-------|--------|--------\n",
    "8      | 0.2    | Male\n",
    "12     | 5.7    | Male\n",
    "11     | 5.7    | Male\n",
    "11     | 7.9    | Male\n",
    "4      | 1.8    | Female\n",
    "5      | 2.4    | Female\n",
    "16     | 4.8    | Female\n",
    "13     | 9.2    | Female\n",
    "\n",
    "a.  What is the SSE of this partition?\n",
    "\n",
    "**Response:** 116\n",
    "\n",
    "b.  If this partition was split using the rule `Rating < 3.6` vs. `Rating >= 3.6`, what would be the SSEs of each resulting partition and the *fraction reduction* in the SSE when this rule is used (the fractional reduction is the reduction in SSE divided by the SSE of the original partition)?   If the `cp` value for the tree was 0.01 (default in R), would this partition be split (assuming it's the first rule added to the model)?  \n",
    "\n",
    "**Response:**  The fractional reduction in `SSE` works out to be about 0.78 (from 0 to 0.777), wow that's huge  Since this is (much) larger than `cp`, so yes the partition could be split using this rule.\n",
    "\n",
    "c.  If this partition was split using the rule `Gender=Female` vs. `Gender=Male`, would would be SSEs of each resulting partition and the the *fraction reduction* in the SSE when this rule is used?   If the `cp` value for the tree was 0.01 (default in R), would this partition be split (assuming it's the first rule added to the model)?  \n",
    "\n",
    "**Response:**  The fractional reduction in `SSE` works out to be about 0.017 (from 0 to 0.01724138).  Since this is larger than `cp`, so yes the partition could be split using this rule.\n",
    "\n",
    "d.  Which of the two rules:  `Rating < 3.6` vs. `Rating >= 3.6` or `Gender=Female` vs. `Gender=Male` is better and why?\n",
    "\n",
    "**Response:**  The rating rule is better because it gives the largest reduction in SSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.742546Z",
     "start_time": "2020-03-29T03:18:52.008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "116"
      ],
      "text/latex": [
       "116"
      ],
      "text/markdown": [
       "116"
      ],
      "text/plain": [
       "[1] 116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "90.1333333333333"
      ],
      "text/latex": [
       "90.1333333333333"
      ],
      "text/markdown": [
       "90.1333333333333"
      ],
      "text/plain": [
       "[1] 90.13333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.777011494252874"
      ],
      "text/latex": [
       "0.777011494252874"
      ],
      "text/markdown": [
       "0.777011494252874"
      ],
      "text/plain": [
       "[1] 0.7770115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2"
      ],
      "text/latex": [
       "2"
      ],
      "text/markdown": [
       "2"
      ],
      "text/plain": [
       "[1] 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0172413793103448"
      ],
      "text/latex": [
       "0.0172413793103448"
      ],
      "text/markdown": [
       "0.0172413793103448"
      ],
      "text/plain": [
       "[1] 0.01724138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculate SSE of partition\n",
    "y <- c(8,4,5,16,12,11,11,13)\n",
    "x <- c(.2,1.8,2.4,4.8,5.7,5.7,7.9,9.2)\n",
    "g <- c(\"Male\",\"Female\",\"Female\",\"Female\",\"Male\",\"Male\",\"Male\",\"Female\")\n",
    "sum( (y-mean(y))^2 )\n",
    "\n",
    "#Splitting x < 3.6 vs. x >= 3.6\n",
    "n1 <- 3    #Get SSE of left\n",
    "y.left <- y[1:3]\n",
    "SSE1 <- sum( (y.left-mean(y.left))^2 )\n",
    "\n",
    "n2 <- 5  #Get SSE of right\n",
    "y.right <- y[-(1:3)]\n",
    "SSE2 <- sum( (y.right-mean(y.right))^2 )\n",
    "\n",
    "SSE.orig <- sum( (y-mean(y))^2 )\n",
    "SSE.new <- SSE1+SSE2\n",
    "SSE.orig-SSE.new  #reduction in SSE\n",
    "(SSE.orig-SSE.new)/SSE.orig  #fractional reduction in R^2\n",
    "\n",
    "#Splitting Male vs. Female\n",
    "y.left <- y[which(g==\"Male\")]; n1 <- length(y.left)  \n",
    "SSE1 <- sum( (y.left-mean(y.left))^2 )\n",
    "y.right <- y[which(g==\"Female\")]; n2 <- length(y.right)\n",
    "SSE2 <- sum( (y.right-mean(y.right))^2 )\n",
    "\n",
    "SSE.orig <- sum( (y-mean(y))^2 )\n",
    "SSE.new <- SSE1+SSE2\n",
    "SSE.orig-SSE.new  #reduction in SSE\n",
    "(SSE.orig-SSE.new)/SSE.orig  #fractional reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Trees\n",
    "\n",
    "Load in the `CHURN` data for a classification problem where we predict whether or not a customer renews their contract with a telecommunications company (think Verizon, ATT, etc.).  The column `churn` lets us know if the customer \"churned\" (left) or not (levels are `Yes` or `No`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.777325Z",
     "start_time": "2020-03-29T03:18:52.063Z"
    }
   },
   "outputs": [],
   "source": [
    "data(CHURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.  Randomly split the data in 70% training (call it `TRAIN`) and 30% holdout (call it `HOLDOUT`).  Immediately before the `sample` command, make sure to run `set.seed(474)` so we all get the same results.  Verify the `head` and `tail` commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.863934Z",
     "start_time": "2020-03-29T03:18:52.114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>churn</th><th scope=col>accountlength</th><th scope=col>internationalplan</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>4950</th><td>No</td><td>154</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>3949</th><td>No</td><td>108</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>2649</th><td>No</td><td>131</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>405</th><td>No</td><td> 73</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>3463</th><td>No</td><td>133</td><td>no</td></tr>\n",
       "\t<tr><th scope=row>2479</th><td>No</td><td>123</td><td>no</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & churn & accountlength & internationalplan\\\\\n",
       "  & <fct> & <int> & <fct>\\\\\n",
       "\\hline\n",
       "\t4950 & No & 154 & no\\\\\n",
       "\t3949 & No & 108 & no\\\\\n",
       "\t2649 & No & 131 & no\\\\\n",
       "\t405 & No &  73 & no\\\\\n",
       "\t3463 & No & 133 & no\\\\\n",
       "\t2479 & No & 123 & no\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | churn &lt;fct&gt; | accountlength &lt;int&gt; | internationalplan &lt;fct&gt; |\n",
       "|---|---|---|---|\n",
       "| 4950 | No | 154 | no |\n",
       "| 3949 | No | 108 | no |\n",
       "| 2649 | No | 131 | no |\n",
       "| 405 | No |  73 | no |\n",
       "| 3463 | No | 133 | no |\n",
       "| 2479 | No | 123 | no |\n",
       "\n"
      ],
      "text/plain": [
       "     churn accountlength internationalplan\n",
       "4950 No    154           no               \n",
       "3949 No    108           no               \n",
       "2649 No    131           no               \n",
       "405  No     73           no               \n",
       "3463 No    133           no               \n",
       "2479 No    123           no               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>churn</th><th scope=col>accountlength</th><th scope=col>internationalplan</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>9</th><td>No </td><td>117</td><td>no </td></tr>\n",
       "\t<tr><th scope=row>10</th><td>No </td><td>141</td><td>yes</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>No </td><td> 74</td><td>no </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>No </td><td> 95</td><td>no </td></tr>\n",
       "\t<tr><th scope=row>16</th><td>Yes</td><td>161</td><td>no </td></tr>\n",
       "\t<tr><th scope=row>23</th><td>No </td><td>130</td><td>no </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & churn & accountlength & internationalplan\\\\\n",
       "  & <fct> & <int> & <fct>\\\\\n",
       "\\hline\n",
       "\t9 & No  & 117 & no \\\\\n",
       "\t10 & No  & 141 & yes\\\\\n",
       "\t12 & No  &  74 & no \\\\\n",
       "\t14 & No  &  95 & no \\\\\n",
       "\t16 & Yes & 161 & no \\\\\n",
       "\t23 & No  & 130 & no \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | churn &lt;fct&gt; | accountlength &lt;int&gt; | internationalplan &lt;fct&gt; |\n",
       "|---|---|---|---|\n",
       "| 9 | No  | 117 | no  |\n",
       "| 10 | No  | 141 | yes |\n",
       "| 12 | No  |  74 | no  |\n",
       "| 14 | No  |  95 | no  |\n",
       "| 16 | Yes | 161 | no  |\n",
       "| 23 | No  | 130 | no  |\n",
       "\n"
      ],
      "text/plain": [
       "   churn accountlength internationalplan\n",
       "9  No    117           no               \n",
       "10 No    141           yes              \n",
       "12 No     74           no               \n",
       "14 No     95           no               \n",
       "16 Yes   161           no               \n",
       "23 No    130           no               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(474)\n",
    "train.rows <- sample(1:nrow(CHURN),0.70*nrow(CHURN))\n",
    "TRAIN <- CHURN[train.rows,]\n",
    "HOLDOUT <- CHURN[-train.rows,]\n",
    "head(TRAIN[,1:3])\n",
    "head(HOLDOUT[,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  Based on the distribution of classes in the training set, what will the naive model classify everyone in the holdout sample (class Yes or class No)?  What is the accuracy of the naive model on the holdout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:54.902289Z",
     "start_time": "2020-03-29T03:18:52.161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  No  Yes \n",
       "3012  488 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.860571428571429"
      ],
      "text/latex": [
       "0.860571428571429"
      ],
      "text/markdown": [
       "0.860571428571429"
      ],
      "text/plain": [
       "[1] 0.8605714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.854"
      ],
      "text/latex": [
       "0.854"
      ],
      "text/markdown": [
       "0.854"
      ],
      "text/plain": [
       "[1] 0.854"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(TRAIN$churn)  #will classify everything as 'No'\n",
    "mean(TRAIN$churn==\"No\")  #estimated accuracy of naive model \n",
    "mean(HOLDOUT$churn==\"No\") #actual accuracy on the holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.  Using `train`, estimate the generalization error (accuracy) of a logistic regression model from the training data (use all predictors, no interactions).  Then, make predictions on the holdout and find its actual accuracy and AUC.  Note:  `trainControl` should be set up to be tuning on accuracy, vanilla 5-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:56.138716Z",
     "start_time": "2020-03-29T03:18:52.209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>parameter</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>none</td><td>0.8677207</td><td>0.2429164</td><td>0.01136066</td><td>0.05046288</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & parameter & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <fct> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & none & 0.8677207 & 0.2429164 & 0.01136066 & 0.05046288\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | parameter &lt;fct&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | none | 0.8677207 | 0.2429164 | 0.01136066 | 0.05046288 |\n",
       "\n"
      ],
      "text/plain": [
       "  parameter Accuracy  Kappa     AccuracySD KappaSD   \n",
       "1 none      0.8677207 0.2429164 0.01136066 0.05046288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.860666666666667"
      ],
      "text/latex": [
       "0.860666666666667"
      ],
      "text/markdown": [
       "0.860666666666667"
      ],
      "text/plain": [
       "[1] 0.8606667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.860666666666667</dd><dt>Kappa</dt><dd>0.245639870639871</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.860666666666667\n",
       "\\item[Kappa] 0.245639870639871\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.860666666666667Kappa\n",
       ":   0.245639870639871\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.8606667 0.2456399 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = No, case = Yes\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "roc.default(response = HOLDOUT$churn, predictor = predict(GLM,     newdata = HOLDOUT, type = \"prob\")$Yes)\n",
       "\n",
       "Data: predict(GLM, newdata = HOLDOUT, type = \"prob\")$Yes in 1281 controls (HOLDOUT$churn No) < 219 cases (HOLDOUT$churn Yes).\n",
       "Area under the curve: 0.8321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fitControl <- trainControl(method=\"cv\",number=5,classProbs=TRUE) \n",
    "set.seed(474)\n",
    "GLM <- train(churn~.,data=TRAIN,method=\"glm\",trControl=fitControl,preProc=c(\"center\",\"scale\"))\n",
    "GLM$results\n",
    "mean( HOLDOUT$churn == predict(GLM,newdata=HOLDOUT) )\n",
    "postResample( predict(GLM,newdata=HOLDOUT), HOLDOUT$churn)\n",
    "roc(HOLDOUT$churn,predict(GLM,newdata=HOLDOUT,type=\"prob\")$Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d.  Using `train` and the values of `cp` in the code below, find the best estimated generalization error/accuracy of a vanilla partition model. Make predictions on the holdout and find its actual accuracy and AUC.\n",
    "\n",
    "**Selected cp:**  0.001887392\n",
    "**Estimated accuracy:**  0.9482857\n",
    "**Actual accuracy on holdout:** 0.9373333   \n",
    "**Actual AUC on holdout:** 0.9169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:58.282182Z",
     "start_time": "2020-03-29T03:18:52.257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>cp</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>19</th><td>0.001268961</td><td>0.946571</td><td>0.7587462</td><td>0.005773457</td><td>0.02705771</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & cp & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t19 & 0.001268961 & 0.946571 & 0.7587462 & 0.005773457 & 0.02705771\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | cp &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 19 | 0.001268961 | 0.946571 | 0.7587462 | 0.005773457 | 0.02705771 |\n",
       "\n"
      ],
      "text/plain": [
       "   cp          Accuracy Kappa     AccuracySD  KappaSD   \n",
       "19 0.001268961 0.946571 0.7587462 0.005773457 0.02705771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.948"
      ],
      "text/latex": [
       "0.948"
      ],
      "text/markdown": [
       "0.948"
      ],
      "text/plain": [
       "[1] 0.948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.948</dd><dt>Kappa</dt><dd>0.776224739215754</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.948\n",
       "\\item[Kappa] 0.776224739215754\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.948Kappa\n",
       ":   0.776224739215754\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.9480000 0.7762247 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = No, case = Yes\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "roc.default(response = HOLDOUT$churn, predictor = predict(RPARTfit,     newdata = HOLDOUT, type = \"prob\")$Yes)\n",
       "\n",
       "Data: predict(RPARTfit, newdata = HOLDOUT, type = \"prob\")$Yes in 1281 controls (HOLDOUT$churn No) < 219 cases (HOLDOUT$churn Yes).\n",
       "Area under the curve: 0.9038"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The following values of cp are a good place to start when tuning a vanilla partition model\n",
    "rpartGrid <- expand.grid(cp=10^seq(from=-6,to=-1,length=30))\n",
    "set.seed(474)\n",
    "RPARTfit <- train(churn~.,data=TRAIN,method=\"rpart\",tuneGrid=rpartGrid,\n",
    "                                  trControl=fitControl,preProc=c(\"center\",\"scale\"))\n",
    "RPARTfit$results[rownames( RPARTfit$bestTune ),]\n",
    "\n",
    "mean( HOLDOUT$churn == predict(RPARTfit,newdata=HOLDOUT) )\n",
    "postResample( predict(RPARTfit,newdata=HOLDOUT),  HOLDOUT$churn)\n",
    "roc(HOLDOUT$churn,predict(RPARTfit,newdata=HOLDOUT,type=\"prob\")$Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.  Fit the model using `rpart` and a `cp=0.05` (not the optimal value, but large enough so that the tree can be plotted) and use `visualize_model` to see what the tree looks like.  Consider the tenth individual in `CHURN`, i.e., `CHURN[10,]`.  By manually following the rules down the tree, what does the model predict for the probabilities of churning/not churning?  Does the model make a correct prediction for this individual?\n",
    "\n",
    "**Prediction:**  Is `totaldayminutes < 264`?  Yes, head to the left.  Is `numbercustomerservicecalls<4`?  Yes, head to the left. `internationalplan=no`? No, head to the right. `totalintlcalls>=3`? Yes, head to the left. `totalintlminutes<13`? Yes, head to the left. The prediction is `No` with 95.1% chance (183 other individuals match this set of characteristics). The prediction is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:18:59.070027Z",
     "start_time": "2020-03-29T03:18:52.303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 18</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>churn</th><th scope=col>accountlength</th><th scope=col>internationalplan</th><th scope=col>voicemailplan</th><th scope=col>numbervmailmessages</th><th scope=col>totaldayminutes</th><th scope=col>totaldaycalls</th><th scope=col>totaldaycharge</th><th scope=col>totaleveminutes</th><th scope=col>totalevecalls</th><th scope=col>totalevecharge</th><th scope=col>totalnightminutes</th><th scope=col>totalnightcalls</th><th scope=col>totalnightcharge</th><th scope=col>totalintlminutes</th><th scope=col>totalintlcalls</th><th scope=col>totalintlcharge</th><th scope=col>numbercustomerservicecalls</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>10</th><td>No</td><td>141</td><td>yes</td><td>yes</td><td>37</td><td>258.6</td><td>84</td><td>43.96</td><td>222</td><td>111</td><td>18.87</td><td>326.4</td><td>97</td><td>14.69</td><td>11.2</td><td>5</td><td>3.02</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 18\n",
       "\\begin{tabular}{r|llllllllllllllllll}\n",
       "  & churn & accountlength & internationalplan & voicemailplan & numbervmailmessages & totaldayminutes & totaldaycalls & totaldaycharge & totaleveminutes & totalevecalls & totalevecharge & totalnightminutes & totalnightcalls & totalnightcharge & totalintlminutes & totalintlcalls & totalintlcharge & numbercustomerservicecalls\\\\\n",
       "  & <fct> & <int> & <fct> & <fct> & <int> & <dbl> & <int> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <int> & <dbl> & <dbl> & <int> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t10 & No & 141 & yes & yes & 37 & 258.6 & 84 & 43.96 & 222 & 111 & 18.87 & 326.4 & 97 & 14.69 & 11.2 & 5 & 3.02 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 18\n",
       "\n",
       "| <!--/--> | churn &lt;fct&gt; | accountlength &lt;int&gt; | internationalplan &lt;fct&gt; | voicemailplan &lt;fct&gt; | numbervmailmessages &lt;int&gt; | totaldayminutes &lt;dbl&gt; | totaldaycalls &lt;int&gt; | totaldaycharge &lt;dbl&gt; | totaleveminutes &lt;dbl&gt; | totalevecalls &lt;int&gt; | totalevecharge &lt;dbl&gt; | totalnightminutes &lt;dbl&gt; | totalnightcalls &lt;int&gt; | totalnightcharge &lt;dbl&gt; | totalintlminutes &lt;dbl&gt; | totalintlcalls &lt;int&gt; | totalintlcharge &lt;dbl&gt; | numbercustomerservicecalls &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 10 | No | 141 | yes | yes | 37 | 258.6 | 84 | 43.96 | 222 | 111 | 18.87 | 326.4 | 97 | 14.69 | 11.2 | 5 | 3.02 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "   churn accountlength internationalplan voicemailplan numbervmailmessages\n",
       "10 No    141           yes               yes           37                 \n",
       "   totaldayminutes totaldaycalls totaldaycharge totaleveminutes totalevecalls\n",
       "10 258.6           84            43.96          222             111          \n",
       "   totalevecharge totalnightminutes totalnightcalls totalnightcharge\n",
       "10 18.87          326.4             97              14.69           \n",
       "   totalintlminutes totalintlcalls totalintlcharge numbercustomerservicecalls\n",
       "10 11.2             5              3.02            0                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      },
      "text/plain": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TREE <- rpart(churn~.,data=TRAIN,cp=0.05)\n",
    "visualize_model(TREE)\n",
    "CHURN[10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f.  Using `train` and the values of `mtry` in the code below (corresponding to 2, then the default value for this dataset of 4, then the value for pure bagging which is all predictors), find the estimated generalization error/accuracy of a random forest model (use the `mtry` associated with the lowest estimated generalization error).   Note:  `train` will need a minute or two to finish.  Then, make predictions on the holdout and find its actual accuracy and AUC.\n",
    "\n",
    "**Selected mtry:**  4\n",
    "**Estimated accuracy:**  0.9597143\n",
    "**Actual accuracy on holdout:** 0.9520000   \n",
    "**Actual AUC on holdout:** 0.9216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:19:43.959655Z",
     "start_time": "2020-03-29T03:18:52.351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 3 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mtry</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 2</td><td>0.9414297</td><td>0.7079328</td><td>0.002637134</td><td>0.01582238</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 4</td><td>0.9528571</td><td>0.7785188</td><td>0.003030832</td><td>0.01627000</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>17</td><td>0.9525706</td><td>0.7828362</td><td>0.005296891</td><td>0.02560711</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & mtry & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  2 & 0.9414297 & 0.7079328 & 0.002637134 & 0.01582238\\\\\n",
       "\t2 &  4 & 0.9528571 & 0.7785188 & 0.003030832 & 0.01627000\\\\\n",
       "\t3 & 17 & 0.9525706 & 0.7828362 & 0.005296891 & 0.02560711\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 5\n",
       "\n",
       "| <!--/--> | mtry &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 |  2 | 0.9414297 | 0.7079328 | 0.002637134 | 0.01582238 |\n",
       "| 2 |  4 | 0.9528571 | 0.7785188 | 0.003030832 | 0.01627000 |\n",
       "| 3 | 17 | 0.9525706 | 0.7828362 | 0.005296891 | 0.02560711 |\n",
       "\n"
      ],
      "text/plain": [
       "  mtry Accuracy  Kappa     AccuracySD  KappaSD   \n",
       "1  2   0.9414297 0.7079328 0.002637134 0.01582238\n",
       "2  4   0.9528571 0.7785188 0.003030832 0.01627000\n",
       "3 17   0.9525706 0.7828362 0.005296891 0.02560711"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mtry</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>4</td><td>0.9528571</td><td>0.7785188</td><td>0.003030832</td><td>0.01627</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & mtry & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t2 & 4 & 0.9528571 & 0.7785188 & 0.003030832 & 0.01627\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | mtry &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 2 | 4 | 0.9528571 | 0.7785188 | 0.003030832 | 0.01627 |\n",
       "\n"
      ],
      "text/plain": [
       "  mtry Accuracy  Kappa     AccuracySD  KappaSD\n",
       "2 4    0.9528571 0.7785188 0.003030832 0.01627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.952666666666667"
      ],
      "text/latex": [
       "0.952666666666667"
      ],
      "text/markdown": [
       "0.952666666666667"
      ],
      "text/plain": [
       "[1] 0.9526667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.952666666666667</dd><dt>Kappa</dt><dd>0.792514144106233</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.952666666666667\n",
       "\\item[Kappa] 0.792514144106233\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.952666666666667Kappa\n",
       ":   0.792514144106233\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.9526667 0.7925141 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = No, case = Yes\n",
      "\n",
      "Setting direction: controls < cases\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "roc.default(response = HOLDOUT$churn, predictor = predict(FORESTfit,     newdata = HOLDOUT, type = \"prob\")$Yes)\n",
       "\n",
       "Data: predict(FORESTfit, newdata = HOLDOUT, type = \"prob\")$Yes in 1281 controls (HOLDOUT$churn No) < 219 cases (HOLDOUT$churn Yes).\n",
       "Area under the curve: 0.9144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forestGrid <- expand.grid(mtry=c(2,4,17))  \n",
    "set.seed(474)\n",
    "FORESTfit <- train(churn~.,data=TRAIN,method=\"rf\",tuneGrid=forestGrid,\n",
    "                                   trControl=fitControl,preProc=c(\"center\",\"scale\"))\n",
    "\n",
    "FORESTfit$results\n",
    "FORESTfit$results[rownames( FORESTfit$bestTune ),]\n",
    "\n",
    "mean( HOLDOUT$churn == predict(FORESTfit,newdata=HOLDOUT) )\n",
    "postResample( predict(FORESTfit,newdata=HOLDOUT),  HOLDOUT$churn)\n",
    "roc(HOLDOUT$churn,predict(FORESTfit,newdata=HOLDOUT,type=\"prob\")$Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g.  Comment on which model we would choose going forward and why.  Do you see indications of these models being \"overfit\"?    Why or why not?\n",
    "\n",
    "**Response:** We choose the model based on its estimated generalization error. In terms of accuracy, the one standard deviation rule suggests that the random forest models provide a valid choice.\n",
    "\n",
    "There's no signs of overfitting since the actual accuracies on the holdout are about what was estimated. An overfit model would have an accuracy that is substantially lower on the holdout than estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:19:44.144344Z",
     "start_time": "2020-03-29T03:18:52.429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>parameter</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>none</td><td>0.8677207</td><td>0.2429164</td><td>0.01136066</td><td>0.05046288</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & parameter & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <fct> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & none & 0.8677207 & 0.2429164 & 0.01136066 & 0.05046288\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | parameter &lt;fct&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | none | 0.8677207 | 0.2429164 | 0.01136066 | 0.05046288 |\n",
       "\n"
      ],
      "text/plain": [
       "  parameter Accuracy  Kappa     AccuracySD KappaSD   \n",
       "1 none      0.8677207 0.2429164 0.01136066 0.05046288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>cp</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>19</th><td>0.001268961</td><td>0.946571</td><td>0.7587462</td><td>0.005773457</td><td>0.02705771</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & cp & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t19 & 0.001268961 & 0.946571 & 0.7587462 & 0.005773457 & 0.02705771\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | cp &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 19 | 0.001268961 | 0.946571 | 0.7587462 | 0.005773457 | 0.02705771 |\n",
       "\n"
      ],
      "text/plain": [
       "   cp          Accuracy Kappa     AccuracySD  KappaSD   \n",
       "19 0.001268961 0.946571 0.7587462 0.005773457 0.02705771"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mtry</th><th scope=col>Accuracy</th><th scope=col>Kappa</th><th scope=col>AccuracySD</th><th scope=col>KappaSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>4</td><td>0.9528571</td><td>0.7785188</td><td>0.003030832</td><td>0.01627</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & mtry & Accuracy & Kappa & AccuracySD & KappaSD\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t2 & 4 & 0.9528571 & 0.7785188 & 0.003030832 & 0.01627\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| <!--/--> | mtry &lt;dbl&gt; | Accuracy &lt;dbl&gt; | Kappa &lt;dbl&gt; | AccuracySD &lt;dbl&gt; | KappaSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 2 | 4 | 0.9528571 | 0.7785188 | 0.003030832 | 0.01627 |\n",
       "\n"
      ],
      "text/plain": [
       "  mtry Accuracy  Kappa     AccuracySD  KappaSD\n",
       "2 4    0.9528571 0.7785188 0.003030832 0.01627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.860666666666667</dd><dt>Kappa</dt><dd>0.245639870639871</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.860666666666667\n",
       "\\item[Kappa] 0.245639870639871\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.860666666666667Kappa\n",
       ":   0.245639870639871\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.8606667 0.2456399 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.948</dd><dt>Kappa</dt><dd>0.776224739215754</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.948\n",
       "\\item[Kappa] 0.776224739215754\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.948Kappa\n",
       ":   0.776224739215754\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.9480000 0.7762247 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.952666666666667</dd><dt>Kappa</dt><dd>0.792514144106233</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.952666666666667\n",
       "\\item[Kappa] 0.792514144106233\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.952666666666667Kappa\n",
       ":   0.792514144106233\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.9526667 0.7925141 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GLM$results\n",
    "RPARTfit$results[rownames( RPARTfit$bestTune ),]\n",
    "FORESTfit$results[rownames( FORESTfit$bestTune ),]\n",
    "\n",
    "postResample(predict(GLM,newdata=HOLDOUT),HOLDOUT$churn)\n",
    "postResample(predict(RPARTfit,newdata=HOLDOUT),HOLDOUT$churn)\n",
    "postResample(predict(FORESTfit,newdata=HOLDOUT),HOLDOUT$churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:31:37.762893Z",
     "start_time": "2020-03-28T16:27:08.530Z"
    }
   },
   "source": [
    "# GBM and XGBoost Illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For GBM and XGBoost, it is a lot of work to get a \"good\" model.  Let's try with the `CHURN` dataset and set it up so that 5-fold cross-validation will be used to estimate generalization errors, and the AUC will be of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:19:44.163047Z",
     "start_time": "2020-03-29T03:18:52.514Z"
    }
   },
   "outputs": [],
   "source": [
    "fitControl <- trainControl(method = \"cv\", number = 5,\n",
    "                           classProbs = TRUE, summaryFunction = twoClassSummary, verboseIter = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train` and the values of boosted tree parameters in the code below, find the estimated generalization error/accuracy of a vanilla boosted tree. How many models are considered there?\n",
    "\n",
    "Then, make predictions on the holdout and find its actual accuracy.\n",
    "\n",
    "Note 1:  make sure to add `verbose=FALSE` to the `train` command or be buried in output!\n",
    "\n",
    "Note 2:  `train` may need a minute or two to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:20:57.393436Z",
     "start_time": "2020-03-29T03:18:52.560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train.default(x, y, weights = w, ...):\n",
      "“The metric \"Accuracy\" was not in the result set. ROC will be used instead.”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 8 × 10</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>shrinkage</th><th scope=col>interaction.depth</th><th scope=col>n.minobsinnode</th><th scope=col>n.trees</th><th scope=col>ROC</th><th scope=col>Sens</th><th scope=col>Spec</th><th scope=col>ROCSD</th><th scope=col>SensSD</th><th scope=col>SpecSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>5</th><td>0.010</td><td>4</td><td>10</td><td> 500</td><td>0.9213365</td><td>0.9923665</td><td>0.6742058</td><td>0.02025138</td><td>0.0051888080</td><td>0.03544833</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.010</td><td>4</td><td>10</td><td>1000</td><td>0.9212993</td><td>0.9893792</td><td>0.7275615</td><td>0.01850357</td><td>0.0051862123</td><td>0.03492796</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>0.010</td><td>5</td><td>10</td><td>1000</td><td>0.9211759</td><td>0.9897104</td><td>0.7357458</td><td>0.01732349</td><td>0.0035886643</td><td>0.03494083</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0.010</td><td>5</td><td>10</td><td> 500</td><td>0.9206923</td><td>0.9923665</td><td>0.6885756</td><td>0.01985998</td><td>0.0051888080</td><td>0.04207439</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.001</td><td>5</td><td>10</td><td>1000</td><td>0.9010685</td><td>0.9980100</td><td>0.2972438</td><td>0.01106176</td><td>0.0029665910</td><td>0.07659595</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.001</td><td>4</td><td>10</td><td>1000</td><td>0.8896518</td><td>0.9996683</td><td>0.1762255</td><td>0.01740840</td><td>0.0007416478</td><td>0.02843888</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.001</td><td>5</td><td>10</td><td> 500</td><td>0.8858774</td><td>1.0000000</td><td>0.0000000</td><td>0.01518234</td><td>0.0000000000</td><td>0.00000000</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>0.001</td><td>4</td><td>10</td><td> 500</td><td>0.8812538</td><td>1.0000000</td><td>0.0000000</td><td>0.01494906</td><td>0.0000000000</td><td>0.00000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 10\n",
       "\\begin{tabular}{r|llllllllll}\n",
       "  & shrinkage & interaction.depth & n.minobsinnode & n.trees & ROC & Sens & Spec & ROCSD & SensSD & SpecSD\\\\\n",
       "  & <dbl> & <int> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t5 & 0.010 & 4 & 10 &  500 & 0.9213365 & 0.9923665 & 0.6742058 & 0.02025138 & 0.0051888080 & 0.03544833\\\\\n",
       "\t6 & 0.010 & 4 & 10 & 1000 & 0.9212993 & 0.9893792 & 0.7275615 & 0.01850357 & 0.0051862123 & 0.03492796\\\\\n",
       "\t8 & 0.010 & 5 & 10 & 1000 & 0.9211759 & 0.9897104 & 0.7357458 & 0.01732349 & 0.0035886643 & 0.03494083\\\\\n",
       "\t7 & 0.010 & 5 & 10 &  500 & 0.9206923 & 0.9923665 & 0.6885756 & 0.01985998 & 0.0051888080 & 0.04207439\\\\\n",
       "\t4 & 0.001 & 5 & 10 & 1000 & 0.9010685 & 0.9980100 & 0.2972438 & 0.01106176 & 0.0029665910 & 0.07659595\\\\\n",
       "\t2 & 0.001 & 4 & 10 & 1000 & 0.8896518 & 0.9996683 & 0.1762255 & 0.01740840 & 0.0007416478 & 0.02843888\\\\\n",
       "\t3 & 0.001 & 5 & 10 &  500 & 0.8858774 & 1.0000000 & 0.0000000 & 0.01518234 & 0.0000000000 & 0.00000000\\\\\n",
       "\t1 & 0.001 & 4 & 10 &  500 & 0.8812538 & 1.0000000 & 0.0000000 & 0.01494906 & 0.0000000000 & 0.00000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 10\n",
       "\n",
       "| <!--/--> | shrinkage &lt;dbl&gt; | interaction.depth &lt;int&gt; | n.minobsinnode &lt;dbl&gt; | n.trees &lt;dbl&gt; | ROC &lt;dbl&gt; | Sens &lt;dbl&gt; | Spec &lt;dbl&gt; | ROCSD &lt;dbl&gt; | SensSD &lt;dbl&gt; | SpecSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 5 | 0.010 | 4 | 10 |  500 | 0.9213365 | 0.9923665 | 0.6742058 | 0.02025138 | 0.0051888080 | 0.03544833 |\n",
       "| 6 | 0.010 | 4 | 10 | 1000 | 0.9212993 | 0.9893792 | 0.7275615 | 0.01850357 | 0.0051862123 | 0.03492796 |\n",
       "| 8 | 0.010 | 5 | 10 | 1000 | 0.9211759 | 0.9897104 | 0.7357458 | 0.01732349 | 0.0035886643 | 0.03494083 |\n",
       "| 7 | 0.010 | 5 | 10 |  500 | 0.9206923 | 0.9923665 | 0.6885756 | 0.01985998 | 0.0051888080 | 0.04207439 |\n",
       "| 4 | 0.001 | 5 | 10 | 1000 | 0.9010685 | 0.9980100 | 0.2972438 | 0.01106176 | 0.0029665910 | 0.07659595 |\n",
       "| 2 | 0.001 | 4 | 10 | 1000 | 0.8896518 | 0.9996683 | 0.1762255 | 0.01740840 | 0.0007416478 | 0.02843888 |\n",
       "| 3 | 0.001 | 5 | 10 |  500 | 0.8858774 | 1.0000000 | 0.0000000 | 0.01518234 | 0.0000000000 | 0.00000000 |\n",
       "| 1 | 0.001 | 4 | 10 |  500 | 0.8812538 | 1.0000000 | 0.0000000 | 0.01494906 | 0.0000000000 | 0.00000000 |\n",
       "\n"
      ],
      "text/plain": [
       "  shrinkage interaction.depth n.minobsinnode n.trees ROC       Sens     \n",
       "5 0.010     4                 10              500    0.9213365 0.9923665\n",
       "6 0.010     4                 10             1000    0.9212993 0.9893792\n",
       "8 0.010     5                 10             1000    0.9211759 0.9897104\n",
       "7 0.010     5                 10              500    0.9206923 0.9923665\n",
       "4 0.001     5                 10             1000    0.9010685 0.9980100\n",
       "2 0.001     4                 10             1000    0.8896518 0.9996683\n",
       "3 0.001     5                 10              500    0.8858774 1.0000000\n",
       "1 0.001     4                 10              500    0.8812538 1.0000000\n",
       "  Spec      ROCSD      SensSD       SpecSD    \n",
       "5 0.6742058 0.02025138 0.0051888080 0.03544833\n",
       "6 0.7275615 0.01850357 0.0051862123 0.03492796\n",
       "8 0.7357458 0.01732349 0.0035886643 0.03494083\n",
       "7 0.6885756 0.01985998 0.0051888080 0.04207439\n",
       "4 0.2972438 0.01106176 0.0029665910 0.07659595\n",
       "2 0.1762255 0.01740840 0.0007416478 0.02843888\n",
       "3 0.0000000 0.01518234 0.0000000000 0.00000000\n",
       "1 0.0000000 0.01494906 0.0000000000 0.00000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.939333333333333</dd><dt>Kappa</dt><dd>0.718948434758975</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.939333333333333\n",
       "\\item[Kappa] 0.718948434758975\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.939333333333333Kappa\n",
       ":   0.718948434758975\n",
       "\n"
      ],
      "text/plain": [
       " Accuracy     Kappa \n",
       "0.9393333 0.7189484 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbmGrid <- expand.grid(n.trees=c(500,1000),interaction.depth=4:5,shrinkage=c(.001,.01),n.minobsinnode=10)\n",
    "set.seed(474)\n",
    "GBM <- train(churn~.,data=TRAIN,method=\"gbm\",tuneGrid=gbmGrid,verbose=FALSE,\n",
    "                                trControl=fitControl,preProc=c(\"center\",\"scale\"))\n",
    "\n",
    "GBM$results[order(GBM$results$ROC,decreasing=TRUE),]\n",
    "\n",
    "postResample(predict(GBM,newdata=HOLDOUT),HOLDOUT$churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For XGBoost, try the parameters given below and remember `set.seed(474)` immediately before `train`.\n",
    "\n",
    "**Expect the training to take a LONG time ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-29T03:22:27.231959Z",
     "start_time": "2020-03-29T03:18:52.602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 18 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>eta</th><th scope=col>max_depth</th><th scope=col>gamma</th><th scope=col>colsample_bytree</th><th scope=col>min_child_weight</th><th scope=col>subsample</th><th scope=col>nrounds</th><th scope=col>ROC</th><th scope=col>Sens</th><th scope=col>Spec</th><th scope=col>ROCSD</th><th scope=col>SensSD</th><th scope=col>SpecSD</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>6</th><td>0.01</td><td>5</td><td> 1</td><td>1</td><td>1</td><td>0.8</td><td>500</td><td>0.9265708</td><td>0.9933599</td><td>0.7295603</td><td>0.01633504</td><td>0.002625613</td><td>0.025954228</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.01</td><td>5</td><td> 0</td><td>1</td><td>1</td><td>0.8</td><td>500</td><td>0.9264400</td><td>0.9930271</td><td>0.7315801</td><td>0.01757621</td><td>0.004300901</td><td>0.017789384</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>0.01</td><td>7</td><td> 0</td><td>1</td><td>1</td><td>0.8</td><td>500</td><td>0.9253710</td><td>0.9936916</td><td>0.7438881</td><td>0.01516199</td><td>0.003600486</td><td>0.025574012</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>0.01</td><td>7</td><td> 1</td><td>1</td><td>1</td><td>0.8</td><td>500</td><td>0.9248504</td><td>0.9943560</td><td>0.7336419</td><td>0.01575669</td><td>0.003015626</td><td>0.025556200</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>0.01</td><td>7</td><td>10</td><td>1</td><td>1</td><td>0.8</td><td>500</td><td>0.9227653</td><td>0.9923649</td><td>0.6722281</td><td>0.01734850</td><td>0.004780320</td><td>0.036464466</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.01</td><td>5</td><td> 1</td><td>1</td><td>1</td><td>0.8</td><td>200</td><td>0.9220038</td><td>0.9916999</td><td>0.7029245</td><td>0.01627622</td><td>0.003319514</td><td>0.029962788</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>0.01</td><td>5</td><td>10</td><td>1</td><td>1</td><td>0.8</td><td>500</td><td>0.9219451</td><td>0.9920332</td><td>0.6722281</td><td>0.01705913</td><td>0.005298242</td><td>0.037171480</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.01</td><td>5</td><td> 0</td><td>1</td><td>1</td><td>0.8</td><td>200</td><td>0.9216422</td><td>0.9910354</td><td>0.7111298</td><td>0.01799808</td><td>0.003443273</td><td>0.031980840</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>0.01</td><td>7</td><td> 0</td><td>1</td><td>1</td><td>0.8</td><td>200</td><td>0.9183337</td><td>0.9923632</td><td>0.7192931</td><td>0.01446130</td><td>0.004782519</td><td>0.020608974</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>0.01</td><td>7</td><td> 1</td><td>1</td><td>1</td><td>0.8</td><td>200</td><td>0.9181961</td><td>0.9926960</td><td>0.7213549</td><td>0.01496721</td><td>0.003998992</td><td>0.022611349</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>0.01</td><td>7</td><td> 0</td><td>1</td><td>1</td><td>0.8</td><td>100</td><td>0.9178549</td><td>0.9910360</td><td>0.7131706</td><td>0.01745087</td><td>0.004635938</td><td>0.025276300</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>0.01</td><td>5</td><td> 0</td><td>1</td><td>1</td><td>0.8</td><td>100</td><td>0.9165401</td><td>0.9913687</td><td>0.6844098</td><td>0.01948663</td><td>0.004128552</td><td>0.011610068</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>0.01</td><td>7</td><td> 1</td><td>1</td><td>1</td><td>0.8</td><td>100</td><td>0.9157524</td><td>0.9910360</td><td>0.7151904</td><td>0.01857823</td><td>0.003820149</td><td>0.024021919</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.01</td><td>5</td><td> 1</td><td>1</td><td>1</td><td>0.8</td><td>100</td><td>0.9152624</td><td>0.9910371</td><td>0.6762466</td><td>0.01837436</td><td>0.004324626</td><td>0.008156172</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>0.01</td><td>7</td><td>10</td><td>1</td><td>1</td><td>0.8</td><td>200</td><td>0.9146083</td><td>0.9910371</td><td>0.6783716</td><td>0.01565427</td><td>0.003818593</td><td>0.036293752</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>0.01</td><td>5</td><td>10</td><td>1</td><td>1</td><td>0.8</td><td>200</td><td>0.9138371</td><td>0.9903732</td><td>0.6783295</td><td>0.01655000</td><td>0.005168084</td><td>0.036775725</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>0.01</td><td>7</td><td>10</td><td>1</td><td>1</td><td>0.8</td><td>100</td><td>0.9137483</td><td>0.9887137</td><td>0.6598359</td><td>0.01697868</td><td>0.005296305</td><td>0.025424613</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0.01</td><td>5</td><td>10</td><td>1</td><td>1</td><td>0.8</td><td>100</td><td>0.9127114</td><td>0.9893781</td><td>0.6536293</td><td>0.01751259</td><td>0.005320829</td><td>0.027406077</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 18 × 13\n",
       "\\begin{tabular}{r|lllllllllllll}\n",
       "  & eta & max\\_depth & gamma & colsample\\_bytree & min\\_child\\_weight & subsample & nrounds & ROC & Sens & Spec & ROCSD & SensSD & SpecSD\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t6 & 0.01 & 5 &  1 & 1 & 1 & 0.8 & 500 & 0.9265708 & 0.9933599 & 0.7295603 & 0.01633504 & 0.002625613 & 0.025954228\\\\\n",
       "\t3 & 0.01 & 5 &  0 & 1 & 1 & 0.8 & 500 & 0.9264400 & 0.9930271 & 0.7315801 & 0.01757621 & 0.004300901 & 0.017789384\\\\\n",
       "\t12 & 0.01 & 7 &  0 & 1 & 1 & 0.8 & 500 & 0.9253710 & 0.9936916 & 0.7438881 & 0.01516199 & 0.003600486 & 0.025574012\\\\\n",
       "\t15 & 0.01 & 7 &  1 & 1 & 1 & 0.8 & 500 & 0.9248504 & 0.9943560 & 0.7336419 & 0.01575669 & 0.003015626 & 0.025556200\\\\\n",
       "\t18 & 0.01 & 7 & 10 & 1 & 1 & 0.8 & 500 & 0.9227653 & 0.9923649 & 0.6722281 & 0.01734850 & 0.004780320 & 0.036464466\\\\\n",
       "\t5 & 0.01 & 5 &  1 & 1 & 1 & 0.8 & 200 & 0.9220038 & 0.9916999 & 0.7029245 & 0.01627622 & 0.003319514 & 0.029962788\\\\\n",
       "\t9 & 0.01 & 5 & 10 & 1 & 1 & 0.8 & 500 & 0.9219451 & 0.9920332 & 0.6722281 & 0.01705913 & 0.005298242 & 0.037171480\\\\\n",
       "\t2 & 0.01 & 5 &  0 & 1 & 1 & 0.8 & 200 & 0.9216422 & 0.9910354 & 0.7111298 & 0.01799808 & 0.003443273 & 0.031980840\\\\\n",
       "\t11 & 0.01 & 7 &  0 & 1 & 1 & 0.8 & 200 & 0.9183337 & 0.9923632 & 0.7192931 & 0.01446130 & 0.004782519 & 0.020608974\\\\\n",
       "\t14 & 0.01 & 7 &  1 & 1 & 1 & 0.8 & 200 & 0.9181961 & 0.9926960 & 0.7213549 & 0.01496721 & 0.003998992 & 0.022611349\\\\\n",
       "\t10 & 0.01 & 7 &  0 & 1 & 1 & 0.8 & 100 & 0.9178549 & 0.9910360 & 0.7131706 & 0.01745087 & 0.004635938 & 0.025276300\\\\\n",
       "\t1 & 0.01 & 5 &  0 & 1 & 1 & 0.8 & 100 & 0.9165401 & 0.9913687 & 0.6844098 & 0.01948663 & 0.004128552 & 0.011610068\\\\\n",
       "\t13 & 0.01 & 7 &  1 & 1 & 1 & 0.8 & 100 & 0.9157524 & 0.9910360 & 0.7151904 & 0.01857823 & 0.003820149 & 0.024021919\\\\\n",
       "\t4 & 0.01 & 5 &  1 & 1 & 1 & 0.8 & 100 & 0.9152624 & 0.9910371 & 0.6762466 & 0.01837436 & 0.004324626 & 0.008156172\\\\\n",
       "\t17 & 0.01 & 7 & 10 & 1 & 1 & 0.8 & 200 & 0.9146083 & 0.9910371 & 0.6783716 & 0.01565427 & 0.003818593 & 0.036293752\\\\\n",
       "\t8 & 0.01 & 5 & 10 & 1 & 1 & 0.8 & 200 & 0.9138371 & 0.9903732 & 0.6783295 & 0.01655000 & 0.005168084 & 0.036775725\\\\\n",
       "\t16 & 0.01 & 7 & 10 & 1 & 1 & 0.8 & 100 & 0.9137483 & 0.9887137 & 0.6598359 & 0.01697868 & 0.005296305 & 0.025424613\\\\\n",
       "\t7 & 0.01 & 5 & 10 & 1 & 1 & 0.8 & 100 & 0.9127114 & 0.9893781 & 0.6536293 & 0.01751259 & 0.005320829 & 0.027406077\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 18 × 13\n",
       "\n",
       "| <!--/--> | eta &lt;dbl&gt; | max_depth &lt;dbl&gt; | gamma &lt;dbl&gt; | colsample_bytree &lt;dbl&gt; | min_child_weight &lt;dbl&gt; | subsample &lt;dbl&gt; | nrounds &lt;dbl&gt; | ROC &lt;dbl&gt; | Sens &lt;dbl&gt; | Spec &lt;dbl&gt; | ROCSD &lt;dbl&gt; | SensSD &lt;dbl&gt; | SpecSD &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 6 | 0.01 | 5 |  1 | 1 | 1 | 0.8 | 500 | 0.9265708 | 0.9933599 | 0.7295603 | 0.01633504 | 0.002625613 | 0.025954228 |\n",
       "| 3 | 0.01 | 5 |  0 | 1 | 1 | 0.8 | 500 | 0.9264400 | 0.9930271 | 0.7315801 | 0.01757621 | 0.004300901 | 0.017789384 |\n",
       "| 12 | 0.01 | 7 |  0 | 1 | 1 | 0.8 | 500 | 0.9253710 | 0.9936916 | 0.7438881 | 0.01516199 | 0.003600486 | 0.025574012 |\n",
       "| 15 | 0.01 | 7 |  1 | 1 | 1 | 0.8 | 500 | 0.9248504 | 0.9943560 | 0.7336419 | 0.01575669 | 0.003015626 | 0.025556200 |\n",
       "| 18 | 0.01 | 7 | 10 | 1 | 1 | 0.8 | 500 | 0.9227653 | 0.9923649 | 0.6722281 | 0.01734850 | 0.004780320 | 0.036464466 |\n",
       "| 5 | 0.01 | 5 |  1 | 1 | 1 | 0.8 | 200 | 0.9220038 | 0.9916999 | 0.7029245 | 0.01627622 | 0.003319514 | 0.029962788 |\n",
       "| 9 | 0.01 | 5 | 10 | 1 | 1 | 0.8 | 500 | 0.9219451 | 0.9920332 | 0.6722281 | 0.01705913 | 0.005298242 | 0.037171480 |\n",
       "| 2 | 0.01 | 5 |  0 | 1 | 1 | 0.8 | 200 | 0.9216422 | 0.9910354 | 0.7111298 | 0.01799808 | 0.003443273 | 0.031980840 |\n",
       "| 11 | 0.01 | 7 |  0 | 1 | 1 | 0.8 | 200 | 0.9183337 | 0.9923632 | 0.7192931 | 0.01446130 | 0.004782519 | 0.020608974 |\n",
       "| 14 | 0.01 | 7 |  1 | 1 | 1 | 0.8 | 200 | 0.9181961 | 0.9926960 | 0.7213549 | 0.01496721 | 0.003998992 | 0.022611349 |\n",
       "| 10 | 0.01 | 7 |  0 | 1 | 1 | 0.8 | 100 | 0.9178549 | 0.9910360 | 0.7131706 | 0.01745087 | 0.004635938 | 0.025276300 |\n",
       "| 1 | 0.01 | 5 |  0 | 1 | 1 | 0.8 | 100 | 0.9165401 | 0.9913687 | 0.6844098 | 0.01948663 | 0.004128552 | 0.011610068 |\n",
       "| 13 | 0.01 | 7 |  1 | 1 | 1 | 0.8 | 100 | 0.9157524 | 0.9910360 | 0.7151904 | 0.01857823 | 0.003820149 | 0.024021919 |\n",
       "| 4 | 0.01 | 5 |  1 | 1 | 1 | 0.8 | 100 | 0.9152624 | 0.9910371 | 0.6762466 | 0.01837436 | 0.004324626 | 0.008156172 |\n",
       "| 17 | 0.01 | 7 | 10 | 1 | 1 | 0.8 | 200 | 0.9146083 | 0.9910371 | 0.6783716 | 0.01565427 | 0.003818593 | 0.036293752 |\n",
       "| 8 | 0.01 | 5 | 10 | 1 | 1 | 0.8 | 200 | 0.9138371 | 0.9903732 | 0.6783295 | 0.01655000 | 0.005168084 | 0.036775725 |\n",
       "| 16 | 0.01 | 7 | 10 | 1 | 1 | 0.8 | 100 | 0.9137483 | 0.9887137 | 0.6598359 | 0.01697868 | 0.005296305 | 0.025424613 |\n",
       "| 7 | 0.01 | 5 | 10 | 1 | 1 | 0.8 | 100 | 0.9127114 | 0.9893781 | 0.6536293 | 0.01751259 | 0.005320829 | 0.027406077 |\n",
       "\n"
      ],
      "text/plain": [
       "   eta  max_depth gamma colsample_bytree min_child_weight subsample nrounds\n",
       "6  0.01 5          1    1                1                0.8       500    \n",
       "3  0.01 5          0    1                1                0.8       500    \n",
       "12 0.01 7          0    1                1                0.8       500    \n",
       "15 0.01 7          1    1                1                0.8       500    \n",
       "18 0.01 7         10    1                1                0.8       500    \n",
       "5  0.01 5          1    1                1                0.8       200    \n",
       "9  0.01 5         10    1                1                0.8       500    \n",
       "2  0.01 5          0    1                1                0.8       200    \n",
       "11 0.01 7          0    1                1                0.8       200    \n",
       "14 0.01 7          1    1                1                0.8       200    \n",
       "10 0.01 7          0    1                1                0.8       100    \n",
       "1  0.01 5          0    1                1                0.8       100    \n",
       "13 0.01 7          1    1                1                0.8       100    \n",
       "4  0.01 5          1    1                1                0.8       100    \n",
       "17 0.01 7         10    1                1                0.8       200    \n",
       "8  0.01 5         10    1                1                0.8       200    \n",
       "16 0.01 7         10    1                1                0.8       100    \n",
       "7  0.01 5         10    1                1                0.8       100    \n",
       "   ROC       Sens      Spec      ROCSD      SensSD      SpecSD     \n",
       "6  0.9265708 0.9933599 0.7295603 0.01633504 0.002625613 0.025954228\n",
       "3  0.9264400 0.9930271 0.7315801 0.01757621 0.004300901 0.017789384\n",
       "12 0.9253710 0.9936916 0.7438881 0.01516199 0.003600486 0.025574012\n",
       "15 0.9248504 0.9943560 0.7336419 0.01575669 0.003015626 0.025556200\n",
       "18 0.9227653 0.9923649 0.6722281 0.01734850 0.004780320 0.036464466\n",
       "5  0.9220038 0.9916999 0.7029245 0.01627622 0.003319514 0.029962788\n",
       "9  0.9219451 0.9920332 0.6722281 0.01705913 0.005298242 0.037171480\n",
       "2  0.9216422 0.9910354 0.7111298 0.01799808 0.003443273 0.031980840\n",
       "11 0.9183337 0.9923632 0.7192931 0.01446130 0.004782519 0.020608974\n",
       "14 0.9181961 0.9926960 0.7213549 0.01496721 0.003998992 0.022611349\n",
       "10 0.9178549 0.9910360 0.7131706 0.01745087 0.004635938 0.025276300\n",
       "1  0.9165401 0.9913687 0.6844098 0.01948663 0.004128552 0.011610068\n",
       "13 0.9157524 0.9910360 0.7151904 0.01857823 0.003820149 0.024021919\n",
       "4  0.9152624 0.9910371 0.6762466 0.01837436 0.004324626 0.008156172\n",
       "17 0.9146083 0.9910371 0.6783716 0.01565427 0.003818593 0.036293752\n",
       "8  0.9138371 0.9903732 0.6783295 0.01655000 0.005168084 0.036775725\n",
       "16 0.9137483 0.9887137 0.6598359 0.01697868 0.005296305 0.025424613\n",
       "7  0.9127114 0.9893781 0.6536293 0.01751259 0.005320829 0.027406077"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>Accuracy</dt><dd>0.958</dd><dt>Kappa</dt><dd>0.817404006677796</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[Accuracy] 0.958\n",
       "\\item[Kappa] 0.817404006677796\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "Accuracy\n",
       ":   0.958Kappa\n",
       ":   0.817404006677796\n",
       "\n"
      ],
      "text/plain": [
       "Accuracy    Kappa \n",
       "0.958000 0.817404 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboostGrid <- expand.grid(eta=0.01,nrounds=c(100,200,500),\n",
    "                           max_depth=c(5, 7),min_child_weight=1,gamma=c(0, 1, 10),colsample_bytree=1,subsample=0.8)\n",
    "set.seed(474)\n",
    "XTREME <- train(churn~.,data=TRAIN,method=\"xgbTree\",tuneGrid=xgboostGrid,metric=\"ROC\",\n",
    "                                trControl=fitControl,verbose=FALSE)\n",
    "\n",
    "XTREME$results[order(XTREME$results$ROC,decreasing=TRUE),]\n",
    "\n",
    "postResample(predict(XTREME,newdata=HOLDOUT),HOLDOUT$churn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: normally, MUCH more tuning of parameters is performed (and with a much higher number of trees); I've just narrowed it down to some reasonable values in the interest of time. You can explore more choices of parameters to achieve even better performance."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "title": "Solutions on Tree Models",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "358.996px",
    "width": "355.985px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209.95px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
